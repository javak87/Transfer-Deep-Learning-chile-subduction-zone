{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seisbench.data as sbd\n",
    "import seisbench.generate as sbg\n",
    "import seisbench.models as sbm\n",
    "from seisbench.util import worker_seeding\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime\n",
    "from torchsummary import summary\n",
    "from pytorch_toolbelt import losses as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set seed to get reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =20\n",
    "torch.backends.cudnn.deterministic= True\n",
    "torch.backends.cudnn.benchmark= False\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 13:54:54,860 | seisbench | WARNING | Check available storage and memory before downloading and general use of Iquique dataset. Dataset size: waveforms.hdf5 ~5Gb, metadata.csv ~2.6Mb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component order:\tZNE\n",
      "SeisBench model\t\tPhaseNet\n",
      "\n",
      "PhaseNet(\n",
      "  (inc): Conv1d(3, 8, kernel_size=(1,), stride=(1,))\n",
      "  (in_bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv1dSame(\n",
      "    (conv): Conv1d(8, 11, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "  )\n",
      "  (bnd1): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1dSame(\n",
      "    (conv): Conv1d(11, 16, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "  )\n",
      "  (bnd2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv1dSame(\n",
      "    (conv): Conv1d(16, 22, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "  )\n",
      "  (bnd3): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1dSame(\n",
      "    (conv): Conv1d(22, 32, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "  )\n",
      "  (bnd4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up1): ConvTranspose1d(32, 22, kernel_size=(7,), stride=(4,), padding=(2,))\n",
      "  (bnu1): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up2): ConvTranspose1d(44, 16, kernel_size=(7,), stride=(4,), padding=(2,), output_padding=(1,))\n",
      "  (bnu2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up3): ConvTranspose1d(32, 11, kernel_size=(7,), stride=(4,), padding=(2,))\n",
      "  (bnu3): BatchNorm1d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (up4): ConvTranspose1d(22, 8, kernel_size=(7,), stride=(4,), padding=(3,))\n",
      "  (bnu4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (out): ConvTranspose1d(16, 3, kernel_size=(1,), stride=(1,))\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = sbm.PhaseNet.from_pretrained(\"instance\")\n",
    "#model = sbm.EQTransformer.from_pretrained(\"original\")\n",
    "#model = sbm.PhaseNet(phases=\"PSN\")\n",
    "model.cuda();\n",
    "data = sbd.Iquique(sampling_rate=100)\n",
    "train, dev, test = data.train_dev_test()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def convert_relu_to_softplus(model):\n",
    "    for child_name, child in model.named_children():\n",
    "        if isinstance(child, nn.Softmax):\n",
    "            setattr(model, child_name, nn.SiLU())\n",
    "        else:\n",
    "            convert_relu_to_softplus(child)\n",
    "\n",
    "new = convert_relu_to_softplus(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    #print(param.requires_grad)\n",
    "\n",
    "model.out.weight.requires_grad = True\n",
    "model.up4.weight.requires_grad = True\n",
    "#model.up3.weight.requires_grad = True\n",
    "#model.up2.weight.requires_grad = True\n",
    "#model.up1.weight.requires_grad = True\n",
    "#model.conv4.conv.weight.requires_grad = True\n",
    "#model.conv3.conv.weight.requires_grad = True\n",
    "\n",
    "#for param in model.parameters():\n",
    "    #param.requires_grad = False\n",
    "    #print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': (array([[198.29475309, 203.29475309, 210.29475309, ..., -28.70524691,\n",
      "        -43.70524691, -61.70524691],\n",
      "       [-67.81648663, -50.81648663, -49.81648663, ..., -91.81648663,\n",
      "        -80.81648663, -66.81648663],\n",
      "       [ 81.47247942,  66.47247942,  56.47247942, ..., -75.52752058,\n",
      "        -55.52752058, -43.52752058]]), {'source_origin_time': '2014-05-01T00:52:20.970000Z', 'source_latitude_deg': -19.4527, 'source_longitude_deg': -69.9762, 'source_depth_km': 57.95, 'path_back_azimuth_deg': 329.936310182, 'station_network_code': 'DG', 'station_code': 'IN17', 'trace_channel': 'HH*', 'station_location_code': nan, 'station_latitude_deg': -20.48, 'station_longitude_deg': -69.35, 'station_elevation_m': 1278.0, 'trace_name': 'bucket0$2,:3,:15552', 'trace_sampling_rate_hz': 100, 'trace_completeness': 1.0, 'trace_has_spikes': False, 'trace_start_time': '2014-05-01T00:52:20.740000Z', 'trace_P_arrival_sample': 2000.0, 'trace_S_arrival_sample': 3551.0, 'trace_name_original': 'DG.IN17.', 'trace_chunk': '', 'trace_component_order': 'ZNE', 'split': 'dev', 'trace_dt_s': 0.01, 'trace_npts': 15552})}\n"
     ]
    }
   ],
   "source": [
    "generator = sbg.GenericGenerator(data)\n",
    "\n",
    "@generator.augmentation\n",
    "def print_state_dict(state_dict):\n",
    "    print(state_dict)\n",
    "\n",
    "generator[2]['X'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_dict = {\n",
    "    \"trace_P_arrival_sample\": \"P\",\n",
    "    \"trace_S_arrival_sample\": \"S\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = sbg.GenericGenerator(train)\n",
    "dev_generator = sbg.GenericGenerator(dev)\n",
    "test_generator = sbg.GenericGenerator(test)\n",
    "\n",
    "augmentations = [\n",
    "    sbg.WindowAroundSample(list(phase_dict.keys()), samples_before=3000, windowlen=6000, selection=\"random\", strategy=\"variable\"),\n",
    "    sbg.RandomWindow(windowlen=3001, strategy=\"pad\"),\n",
    "    sbg.Normalize(demean_axis=-1, amp_norm_axis=-1, amp_norm_type=\"peak\"),\n",
    "    sbg.ChangeDtype(np.float32),\n",
    "    sbg.ProbabilisticLabeller(label_columns=phase_dict, sigma=3, dim=0)\n",
    "]\n",
    "\n",
    "train_generator.add_augmentations(augmentations)\n",
    "dev_generator.add_augmentations(augmentations)\n",
    "test_generator.add_augmentations(augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_workers = 1  # The number of threads used for loading data\n",
    "\n",
    "train_loader = DataLoader(train_generator, batch_size=batch_size, shuffle=True, num_workers=num_workers, worker_init_fn=worker_seeding)\n",
    "dev_loader = DataLoader(dev_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding)\n",
    "test_loader = DataLoader(test_generator, batch_size=batch_size, shuffle=False, num_workers=num_workers, worker_init_fn=worker_seeding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f8a297398a0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 1\n",
    "loss_weight = torch.tensor([1, 1, 0.01]).to(model.device) # PSN\n",
    "#loss_weight = torch.reshape(loss_weight, (1,3,1))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2)\n",
    "#ross_ent = torch.nn.CrossEntropyLoss()\n",
    "weights = torch.FloatTensor([1.0, 1.0, 1.0]).to(model.device)\n",
    "weights = torch.reshape(loss_weight, (1,3,1))\n",
    "print(weights.size())\n",
    "criterion = nn.BCELoss(weight=weights)\n",
    "\n",
    "\n",
    "def loss_fn(y_pred, y_true, eps=1e-5):\n",
    "    # vector cross entropy loss\n",
    "    #h = y_true * torch.log(y_pred + eps)\n",
    "    h = loss_weight*y_true * torch.log(y_pred + eps)\n",
    "    #print (h)\n",
    "    h = h.mean(-1).sum(-1)  # Mean along sample dimension and sum along pick dimension\n",
    "    h = h.mean()  # Mean over batch axis\n",
    "    return -h\n",
    "\n",
    "#criterion = torch.nn.BCELoss()\n",
    "def fo_loss_fn(y_pred, y_true,gamma=3, eps=1e-5):\n",
    "    loss_detec = criterion(y_pred[0].float(), y_true[0].float())\n",
    "    loss_p = criterion(y_pred[1].float(), y_true[1].float())\n",
    "    loss_s = criterion(y_pred[2].float(), y_true[2].float())\n",
    "    loss = (loss_weight[0]*loss_detec + loss_weight[1]*loss_p+ loss_weight[2]*loss_p)/3\n",
    "    return -loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1.0, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    def forward(self, inputs, targets):\n",
    "        '''\n",
    "        :param inputs: batch_size * dim\n",
    "        :param targets: (batch,)\n",
    "        :return:\n",
    "        '''\n",
    "        bce_loss = F.cross_entropy(inputs, targets)\n",
    "        loss = self.alpha * (1 - torch.exp(-bce_loss)) ** self.gamma * bce_loss\n",
    "        return loss\n",
    "\n",
    "focal_loss = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.a = torch.nn.parameter.Parameter(data = torch.tensor(1.), requires_grad = True)\n",
    "\n",
    "\n",
    "    def forward(self, outputs: torch.Tensor, labels: torch.Tensor):\n",
    "        \n",
    "        SMOOTH = 1e-1\n",
    "\n",
    "        n=torch.argmax(labels.to(model.device),axis=1)\n",
    "        m=torch.argmax(outputs,axis=1)\n",
    "        ####\n",
    "        #print(torch.unique(n))\n",
    "        #print('--------- labels-----------')\n",
    "        #print(torch.nn.functional.one_hot(n).sum (dim = 1))\n",
    "        #print('--------- Outputs-----------')\n",
    "        #print(torch.nn.functional.one_hot(m).sum (dim = 1))\n",
    "        ####\n",
    "        arg_labels_p =  torch.where(n == 0, 1, 0)\n",
    "        arg_outputs_p = torch.where(m == 0, 1, 0)\n",
    "    \n",
    "        intersection_p = torch.sum(arg_outputs_p * arg_labels_p)\n",
    "        #print(intersection_p)\n",
    "        union_p = (arg_outputs_p | arg_labels_p).float().sum()       \n",
    "        iou_p = (intersection_p + SMOOTH) / (union_p + SMOOTH) \n",
    "        #print(iou_p)\n",
    "        dic_loss_p = 1 - (2*iou_p)/(iou_p+1)\n",
    "        loss_p = torch.log(torch.cosh(dic_loss_p))\n",
    "        \n",
    "\n",
    "        arg_labels_s =  torch.where(n == 1, 1, 0)\n",
    "        arg_outputs_s = torch.where(m == 1, 1, 0)\n",
    "        \n",
    "        intersection_s = torch.sum(arg_outputs_s * arg_labels_s)\n",
    "        union_s = (arg_outputs_s | arg_labels_s).float().sum()       \n",
    "        iou_s = (intersection_s + SMOOTH) / (union_s + SMOOTH) \n",
    "        dic_loss_s = 1 - (2*iou_s)/(iou_s+1)\n",
    "        loss_s = torch.log(torch.cosh(dic_loss_s))\n",
    "        #loss = dic_loss_p + dic_loss_s\n",
    "        loss = loss_s + loss_p\n",
    "        \n",
    "        \n",
    "        loss = self.a*(loss)\n",
    "        print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_loss = DiceLoss()\n",
    "#dic_loss = L.DiceLoss(mode = 'multiclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch['X'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader,t):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch = next(iter(dataloader))\n",
    "    #for batch_id, batch in enumerate(dataloader):\n",
    "    # Compute prediction and loss\n",
    "    #print(batch[\"X\"].size())\n",
    "    pred = model(batch[\"X\"].to(model.device))\n",
    "    #print(pred)\n",
    "    #print(arg_outputs_s.nonzero().size())\n",
    "    #print(batch[\"X\"])\n",
    "    #print('----------------------')\n",
    "    #print(pred)\n",
    "    #print('--------------------')\n",
    "    #print(batch[\"y\"])\n",
    "\n",
    "    #loss = dic_loss(pred, batch[\"y\"].to(model.device))\n",
    "    #loss =loss_fn(pred, batch[\"y\"].to(model.device))\n",
    "    #loss = criterion(pred, batch[\"y\"].to(model.device))\n",
    "    print(batch[\"y\"].size())\n",
    "    print(pred.size())\n",
    "    loss= criterion(pred.float(), batch[\"y\"].to(model.device).float())\n",
    "    print(loss)\n",
    "    #loss = cross_ent(pred, batch[\"y\"].to(model.device))\n",
    "    #if t % 10 == 0:\n",
    "    #    print(loss)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    #print(torch.autograd.grad(loss, list(model.parameters())))\n",
    "    return loss\n",
    "    '''\n",
    "    if batch_id % 5 == 0:\n",
    "        loss, current = loss.item(), batch_id * batch[\"X\"].shape[0]\n",
    "        print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    '''    \n",
    "\n",
    "def test_loop(dataloader):\n",
    "    #num_batches = len(dataloader)\n",
    "    #test_loss = 0\n",
    "    model.eval()\n",
    "    batch = next(iter(dataloader))\n",
    "    with torch.no_grad():\n",
    "        #for batch in dataloader:\n",
    "        pred = model(batch[\"X\"].to(model.device))\n",
    "        #test_loss= dic_loss(pred, batch[\"y\"].to(model.device)).item()\n",
    "        test_loss = loss_fn(pred, batch[\"y\"].to(model.device)).item()\n",
    "\n",
    "    #test_loss /= num_batches\n",
    "    print(f\"Test avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3001])\n",
      "torch.Size([1, 3, 3001])\n",
      "tensor(0.0103, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8a1a2afe50>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tot_train_loss = np.zeros((1, epochs))\n",
    "tot_test_loss = np.zeros((1, epochs))\n",
    "for t in range(epochs):\n",
    "    #if t % 10 == 0:\n",
    "        #print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss_train = train_loop(train_loader,t)\n",
    "    break\n",
    "    #print(model.parameters())\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad == False:\n",
    "            print('grad_ouput doesnt have grad')\n",
    "    tot_train_loss[0,t]= loss_train.cpu().detach().numpy()\n",
    "    loss_test = train_loop(test_loader,t)\n",
    "    tot_test_loss[0,t]= loss_test.cpu().detach().numpy()\n",
    "    #print(loss.cpu().detach().numpy().tolist())\n",
    "    #break\n",
    "    \n",
    "\n",
    "plt.plot (tot_train_loss[0,:], label='train_loss')\n",
    "plt.plot (tot_test_loss[0,:], label='test_loss')\n",
    "plt.rcParams[\"figure.figsize\"] = (30,8)\n",
    "plt.xlabel('epochs', fontsize=20)\n",
    "plt.ylabel('loss', fontsize=20)\n",
    "plt.tick_params(axis='x', labelsize=16)\n",
    "plt.tick_params(axis='y', labelsize=16)\n",
    "plt.legend(loc='upper right')\n",
    "    #break\n",
    "    #model.eval()\n",
    "    #test_loop(dev_loader)\n",
    "    #test_loop(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('seisbench')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b20746fb6b31a4a3c185d8dc9e67ee27e52a348cdb9134f10f5f04eafa28ce07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
