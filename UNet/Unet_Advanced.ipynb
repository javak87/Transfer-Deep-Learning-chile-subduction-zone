{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Mi_sgkn4yf9-"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/javak/Transfer-Deep-Learning-chile-subduction-zone/UNet/Unet_Advanced.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/javak/Transfer-Deep-Learning-chile-subduction-zone/UNet/Unet_Advanced.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/javak/Transfer-Deep-Learning-chile-subduction-zone/UNet/Unet_Advanced.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39malbumentations\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mA\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/javak/Transfer-Deep-Learning-chile-subduction-zone/UNet/Unet_Advanced.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39malbumentations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpytorch\u001b[39;00m \u001b[39mimport\u001b[39;00m ToTensorV2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/javak/Transfer-Deep-Learning-chile-subduction-zone/UNet/Unet_Advanced.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/javak/Transfer-Deep-Learning-chile-subduction-zone/UNet/Unet_Advanced.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/seisbench/lib/python3.10/site-packages/albumentations/pytorch/__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m absolute_import\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/seisbench/lib/python3.10/site-packages/albumentations/pytorch/transforms.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m functional \u001b[39mas\u001b[39;00m F\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms_interface\u001b[39;00m \u001b[39mimport\u001b[39;00m BasicTransform\n\u001b[1;32m     11\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mToTensorV2\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from model import UNET\n",
        "from utils import (\n",
        "    load_checkpoint,\n",
        "    save_checkpoint,\n",
        "    get_loaders,\n",
        "    check_accuracy,\n",
        "    save_predictions_as_imgs,\n",
        ")\n",
        "\n",
        "# Hyperparameters etc.\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 10\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 384  # 1280 originally\n",
        "IMAGE_WIDTH = 512  # 1918 originally\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "014Zt5lHy4Le"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "if os.path.exists('saved_images/') == False:\n",
        "  os.mkdir(\"saved_images/\")\n",
        "\n",
        "if os.path.exists('/content/data/train_images') == False: \n",
        "  \n",
        "  images = np.array(os.listdir('/content/data/images'))\n",
        "  masks = np.array(os.listdir('/content/data/masks'))\n",
        "  train_images, val_images = train_test_split(images, test_size=0.3, random_state=25)\n",
        "  train_masks, val_masks = train_test_split(masks, test_size=0.3, random_state=25)\n",
        "  train_images_dir = np.char.add(np.array (train_images.shape[0]*['/content/data/images/']),train_images)\n",
        "  val_images_dir = np.char.add(np.array (val_images.shape[0]*['/content/data/images/']),val_images)\n",
        "  if os.path.exists(\"data/train_images/\") == False:\n",
        "    os.mkdir(\"data/train_images/\")\n",
        "  if os.path.exists('data/train_masks/') == False:\n",
        "    os.mkdir(\"data/train_masks/\")\n",
        "  if os.path.exists('data/val_images/') == False:\n",
        "    os.mkdir(\"data/val_images/\")\n",
        "  if os.path.exists('data/val_masks/') == False:\n",
        "    os.mkdir(\"data/val_masks/\")\n",
        "\n",
        "\n",
        "\n",
        "  [shutil.copy(file, \"data/train_images/\") for file in train_images_dir]\n",
        "  [shutil.copy(file, \"data/train_masks/\") for file in train_images_dir]\n",
        "\n",
        "  [shutil.copy(file, \"data/val_images/\") for file in val_images_dir]\n",
        "  [shutil.copy(file, \"data/val_masks/\") for file in val_images_dir]\n",
        "\n",
        "  if os.path.exists('data/images/') == True:\n",
        "    shutil.rmtree('data/images/')\n",
        "\n",
        "  if os.path.exists('data/masks/') == True:\n",
        "    shutil.rmtree('data/masks/')\n",
        "TRAIN_IMG_DIR = \"data/train_images/\"\n",
        "TRAIN_MASK_DIR = \"data/train_masks/\"\n",
        "VAL_IMG_DIR = \"data/val_images/\"\n",
        "VAL_MASK_DIR = \"data/val_masks/\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8EjzKsGVBwS",
        "outputId": "0724c207-3130-4c92-d8a7-26b156c57019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Got 2939207/70385664 with acc 4.18\n",
            "Dice score: 1.9712238311767578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:00<00:00,  1.15s/it, loss=-173]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 2938156/70385664 with acc 4.17\n",
            "Dice score: 1.714235782623291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:03<00:00,  1.19s/it, loss=-190]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 493834/70385664 with acc 0.70\n",
            "Dice score: 1.8519206047058105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:03<00:00,  1.20s/it, loss=-225]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 2936641/70385664 with acc 4.17\n",
            "Dice score: 1.9633547067642212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:03<00:00,  1.20s/it, loss=-246]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 609777/70385664 with acc 0.87\n",
            "Dice score: 1.9586812257766724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:03<00:00,  1.20s/it, loss=-282]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 2938769/70385664 with acc 4.18\n",
            "Dice score: 1.9561361074447632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:03<00:00,  1.20s/it, loss=-265]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 2270868/70385664 with acc 3.23\n",
            "Dice score: 1.9585925340652466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:02<00:00,  1.18s/it, loss=-282]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 1905391/70385664 with acc 2.71\n",
            "Dice score: 1.9710873365402222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:02<00:00,  1.18s/it, loss=-326]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 2939207/70385664 with acc 4.18\n",
            "Dice score: 1.9712238311767578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:03<00:00,  1.19s/it, loss=-322]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 2109569/70385664 with acc 3.00\n",
            "Dice score: 1.9712047576904297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 53/53 [01:03<00:00,  1.19s/it, loss=-367]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Saving checkpoint\n",
            "Got 2939207/70385664 with acc 4.18\n",
            "Dice score: 1.9712238311767578\n"
          ]
        }
      ],
      "source": [
        "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
        "    loop = tqdm(loader)\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
        "\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # update tqdm loop\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "\n",
        "def main():\n",
        "    train_transform = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.1),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    val_transforms = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    train_loader, val_loader = get_loaders(\n",
        "        TRAIN_IMG_DIR,\n",
        "        TRAIN_MASK_DIR,\n",
        "        VAL_IMG_DIR,\n",
        "        VAL_MASK_DIR,\n",
        "        BATCH_SIZE,\n",
        "        train_transform,\n",
        "        val_transforms,\n",
        "        NUM_WORKERS,\n",
        "        PIN_MEMORY,\n",
        "    )\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
        "\n",
        "\n",
        "    check_accuracy(val_loader, model, device=DEVICE)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
        "\n",
        "        # save model\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\":optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "        # check accuracy\n",
        "        check_accuracy(val_loader, model, device=DEVICE)\n",
        "\n",
        "        # print some examples to a folder\n",
        "        if epoch % 5 == 0:\n",
        "          save_predictions_as_imgs(\n",
        "              val_loader, model, folder=\"saved_images\", device=DEVICE\n",
        "          )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJg6QlBlN-ru"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('UNet')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "7683b368361935c1785fe6bb3bd15b0a4ab8423f9fa7237b86dc3b5e2bd2e5ae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
